max_episodes: 500
seed_steps: 15_600
seed_update_ratio: 0.25
buffer_size: 1_000_000
hardcore: false
no_improvement_window: 0

encoder:
  encoder_dim: 48
  num_encoder_layers: 2

world_model:
  mlp_dim: 96
  latent_dim: 208
  value_dropout: 0.005
  num_value_nets: 5
  num_bins: 101
  symlog_min: -10
  symlog_max: 10
  simnorm_dim: 8
  learning_rate: 6e-4
  encoder_learning_rate: 1e-4
  predict_continues: true
  dtype: bfloat16

tdmpc2:
  # Planning
  mpc: True
  horizon: 5
  mppi_iterations: 6
  population_size: 1024
  policy_prior_samples: 32
  num_elites: 64
  min_plan_std: 0.05
  max_plan_std: 2
  temperature: 0.32
  # Optimization
  batch_size: 256
  discount: 0.99
  rho: 0.5
  consistency_coef: 20
  reward_coef: 0.1
  continue_coef: 0.1
  value_coef: 0.1
  entropy_coef: 1e-5
  tau: 0.01
